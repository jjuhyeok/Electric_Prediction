{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nMzAENAkqj53"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
        "from pytorch_forecasting.metrics import QuantileLoss\n",
        "\n",
        "from pytorch_forecasting.data import (\n",
        "    TimeSeriesDataSet,\n",
        "    GroupNormalizer\n",
        ")\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import (\n",
        "    ModelCheckpoint,\n",
        "    EarlyStopping,\n",
        "    LearningRateMonitor\n",
        ")\n",
        "from pytorch_forecasting.metrics import SMAPE\n",
        "from pytorch_forecasting.models import TemporalFusionTransformer\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "#tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "\n",
        "\n",
        "# category columns\n",
        "CATE_COLS = ['building_num', \"mgrp\", 'holiday', 'dow', 'cluster', 'hot']\n",
        "\n",
        "\n",
        "# building cluster based on kmeans\n",
        "CLUSTER = {\n",
        "    # 0 : 건물 기타\n",
        "    0: [i for i in range(1, 15 + 1)],\n",
        "    # 1 : 공공\n",
        "    1: [i for i in range(16, 23 + 1)],\n",
        "    # 2 : 대학교\n",
        "    2: [i for i in range(24, 31 + 1)],\n",
        "    # 3 : 데이터센터\n",
        "    3: [i for i in range(32, 36 + 1)],\n",
        "    # 4 : 백화점 및 아울렛\n",
        "    4: [i for i in range(37, 44 + 1)],\n",
        "    # 5 : 병원\n",
        "    5: [i for i in range(45, 52 + 1)],\n",
        "    # 6 : 상용\n",
        "    6: [i for i in range(53, 60 + 1)],\n",
        "    # 7 : 아파트\n",
        "    7: [i for i in range(61, 68 + 1)],\n",
        "    # 8 : 연구소\n",
        "    8: [i for i in range(69, 76 + 1)],\n",
        "    # 9 : 지식산업센터\n",
        "    9: [i for i in range(77, 84 + 1)],\n",
        "    # 10 : 할인마트\n",
        "    10: [i for i in range(85, 92 + 1)],\n",
        "    # 11 : 호텔 및 리조트\n",
        "    11: [i for i in range(93, 100 + 1)]\n",
        "}\n",
        "\n",
        "# length of training data for prediction (5 weeks)\n",
        "ENCODER_LENGTH_IN_WEEKS = 5\n",
        "\n",
        "# learning rate determined by a cv run with train data less 1 trailing week as validation\n",
        "LRS = [0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306, 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.05099279397234306 , 0.05099279397234306, 0.05099279397234306, 0.05099279397234306,\n",
        "       0.005099279397234306, 0.005099279397234306, 0.005099279397234306, 0.005099279397234306,\n",
        "       0.005099279397234306, 0.005099279397234306, 0.005099279397234306, 0.005099279397234306,\n",
        "       0.005099279397234306, 0.0005099279397234307, 0.0005099279397234307, 0.0005099279397234307,\n",
        "       0.0005099279397234307, 0.0005099279397234307, 0.0005099279397234307]\n",
        "\n",
        "# number of epochs found in cv run\n",
        "NUM_EPOCHS = 60\n",
        "\n",
        "# number of seeds to use\n",
        "NUM_SEEDS = 10\n",
        "\n",
        "BATCH_SIZE = 64 #\n",
        "\n",
        "# hyper parameters determined by cv runs with train data less 1 trailing week as validation\n",
        "PARAMS = {\n",
        "    'gradient_clip_val': 0.9658579636307634,\n",
        "    'hidden_size': 180,\n",
        "    'dropout': 0.19610151695402608,\n",
        "    'hidden_continuous_size': 90,\n",
        "    'attention_head_size': 4,\n",
        "    'learning_rate': 0.08\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yhnQNCFm_BHP"
      },
      "outputs": [],
      "source": [
        "#경로만 자신의 환경에 맞게 잘 설정해주세요!\n",
        "DATAROOT=''\n",
        "CKPTROOT = DATAROOT+\"/ckpts\" # directory for model checkpoints\n",
        "CSVROOT = DATAROOT+\"/csvs\" # directory for prediction outputs\n",
        "SUBFN = DATAROOT+\"/sub.csv\" # final submission file path\n",
        "LOGDIR = DATAROOT+\"/logs\" # pytorch_forecasting requirs logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ggVlz5EVqnzc"
      },
      "outputs": [],
      "source": [
        "building_df = pd.read_csv('building_info.csv', encoding='UTF8')\n",
        "submission_df = pd.read_csv('sample_submission.csv', encoding='UTF8')\n",
        "train_df = pd.read_csv('train.csv', encoding='UTF8')\n",
        "test_df = pd.read_csv('test.csv', encoding='UTF8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8iqG1VwvXgWg"
      },
      "outputs": [],
      "source": [
        "def seed_all(seed):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yDV6x20n-jbD"
      },
      "outputs": [],
      "source": [
        "def __date_prep(df):\n",
        "\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "    df['hour'] = df['datetime'].dt.hour\n",
        "    df['dow'] = df['datetime'].dt.weekday\n",
        "    df['date'] = df['datetime'].dt.date.astype('str')\n",
        "    df['day'] = df['datetime'].dt.day\n",
        "    df['month'] = df['datetime'].dt.month\n",
        "\n",
        "    # FEATURE: saturday, sunday and speical holidays flagged as `holiday` flag\n",
        "    special_days = ['2022-06-06', '2022-08-15']\n",
        "    df['holiday'] = df['dow'].isin([5,6]).astype(int)\n",
        "    df.loc[df.date.isin(special_days), 'holiday'] = 1\n",
        "\n",
        "    # FEATURE: `hot` flag when the next day is holiday\n",
        "    hot = df.groupby('date').first()['holiday'].shift(-1).fillna(0).astype(int)\n",
        "    hot = hot.to_frame().reset_index().rename({'holiday': \"hot\"}, axis=1)\n",
        "    df = df.merge(hot, on='date', how='left')\n",
        "\n",
        "    # FEATURE: `cumhol` - how many days left in 연휴\n",
        "    h = (df.groupby('date').first()['holiday'] != 0).iloc[::-1]\n",
        "    df1 = h.cumsum() - h.cumsum().where(~h).ffill().fillna(0).astype(int).iloc[::-1]\n",
        "    df1 = df1.to_frame().reset_index().rename({'holiday': \"cumhol\"}, axis=1)\n",
        "    df = df.merge(df1, on='date', how='left')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ThIziO2k-eU_"
      },
      "outputs": [],
      "source": [
        "# read data, process date and assign cluster number\n",
        "def __read_df():\n",
        "    train_columns = ['num_datetime', 'building_num', 'datetime', 'temp', 'prec', 'wind','hum' , 'sun', 'solar', 'target']\n",
        "\n",
        "    train_df = pd.read_csv(DATAROOT+'train.csv', skiprows = [0], names=train_columns)\n",
        "    train_df.drop(['sun', 'solar'], axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "    test_columns = [c for c in train_columns if c != 'target']\n",
        "\n",
        "    test_df = pd.read_csv(DATAROOT+'test.csv', skiprows = [0], names=test_columns)\n",
        "    test_df.drop(['sun', 'solar'], axis = 1, inplace = True)\n",
        "\n",
        "    # gfa = gross floor area (연면적), cooling area (냉방면적)\n",
        "    building_columns = ['building_num', 'cat1', 'gfa', 'ca', 'rm1','rm2' , 'rm3']\n",
        "\n",
        "    building_df = pd.read_csv(DATAROOT + 'building_info.csv', skiprows = [0], names = building_columns)\n",
        "\n",
        "    building_df.drop(['cat1', 'rm1', 'rm2', 'rm3'], axis = 1, inplace = True)\n",
        "\n",
        "    train_df = pd.merge(train_df, building_df, how='right', left_on='building_num', right_on='building_num')\n",
        "\n",
        "    test_df = pd.merge(test_df, building_df, how = 'right', left_on = 'building_num', right_on = 'building_num')\n",
        "\n",
        "    __sz = train_df.shape[0]\n",
        "\n",
        "    # assing cluster number to building\n",
        "    for k, nums in CLUSTER.items():\n",
        "        train_df.loc[train_df.building_num.isin(nums), 'cluster'] = k\n",
        "        test_df.loc[test_df.building_num.isin(nums), 'cluster'] = k\n",
        "\n",
        "    train_df = __date_prep(train_df)\n",
        "    test_df = __date_prep(test_df)\n",
        "\n",
        "\n",
        "    return train_df.copy(), test_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6-apayx4NlzB"
      },
      "outputs": [],
      "source": [
        "# add aggregate(mean) target feature for 'cluster', 'building', 'mgrp' per date\n",
        "def add_feats(df):\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    cols = ['target']\n",
        "    stats = ['mean']\n",
        "\n",
        "    # target null in test set to null for other columns care must be taken\n",
        "    g = df.groupby(['date', 'cluster'])\n",
        "    for s in stats:\n",
        "        col_mapper = {c:f\"{s}_{c}_cluster\" for c in cols}\n",
        "        tr = g[cols].transform(s).rename(col_mapper, axis=1)\n",
        "        df = pd.concat([df, tr], axis=1)\n",
        "\n",
        "    g = df.groupby(['date', 'building_num'])\n",
        "    for s in stats:\n",
        "        col_mapper = {c:f\"{s}_{c}_num\" for c in cols}\n",
        "        tr = g[cols].transform(s).rename(col_mapper, axis=1)\n",
        "        df = pd.concat([df, tr], axis=1)\n",
        "\n",
        "    g = df.groupby(['date', 'mgrp'])\n",
        "    for s in stats:\n",
        "        col_mapper = {c:f\"{s}_{c}_mgrp\" for c in cols}\n",
        "        tr = g[cols].transform(s).rename(col_mapper, axis=1)\n",
        "        df = pd.concat([df, tr], axis=1)\n",
        "\n",
        "    g = df.groupby(['date'])\n",
        "    for s in stats:\n",
        "        col_mapper = {c:f\"{s}_{c}\" for c in cols}\n",
        "        tr = g[cols].transform(s).rename(col_mapper, axis=1)\n",
        "        df = pd.concat([df, tr], axis=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "juOi4cHmNwiS"
      },
      "outputs": [],
      "source": [
        "# interpolate NA values in test dataset\n",
        "def interpolate_(test_df):\n",
        "    # https://dacon.io/competitions/official/235736/codeshare/2844?page=1&dtype=recent\n",
        "    # 에서 제안된 방법으로\n",
        "    __methods = {\n",
        "        'temp': 'quadratic',\n",
        "        'wind':'linear',\n",
        "        'hum':'quadratic',\n",
        "        # precipitation : 강수량\n",
        "        'prec':'quadratic',\n",
        "    }\n",
        "\n",
        "    for col, method in __methods.items():\n",
        "        test_df[col] = test_df[col].interpolate(method=method)\n",
        "        if method == 'quadratic':\n",
        "            test_df[col] = test_df[col].interpolate(method='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "a4S6WU6LCHIv"
      },
      "outputs": [],
      "source": [
        "def CDH(xs):\n",
        "    ys = []\n",
        "    for i in range(len(xs)):\n",
        "        if i < 11:\n",
        "            ys.append(np.sum(xs[:(i+1)]-26))\n",
        "        else:\n",
        "            ys.append(np.sum(xs[(i-11):(i+1)]-26))\n",
        "    return np.array(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V3UwkoCaObQ7"
      },
      "outputs": [],
      "source": [
        "# prepare train and test data\n",
        "def prep():\n",
        "\n",
        "    train_df, test_df = __read_df()\n",
        "\n",
        "    # interpolate na in test_df for temperature, windspeed, humidity, precipitation & insolation\n",
        "    interpolate_(train_df)\n",
        "    interpolate_(test_df)\n",
        "\n",
        "    train_df.loc[train_df['prec'].isna(), 'prec'] = 0\n",
        "    test_df.loc[test_df['prec'].isna(), 'prec'] = 0\n",
        "\n",
        "    # FEATURE(mgrp): group buildings having same temperature and windspeed measurements\n",
        "    s = train_df[train_df.datetime=='2022-06-01 00:00:00'].groupby(['temp', 'wind']).ngroup()\n",
        "    s.name = 'mgrp'\n",
        "    mgrps = train_df[['building_num']].join(s, how='inner')\n",
        "\n",
        "    # 불쾌지수 feature 생성\n",
        "    ## https://dacon.io/competitions/official/235736/codeshare/2743?page=1&dtype=recent\n",
        "    train_df['THI'] = 9/5*train_df['temp'] - 0.55*(1-train_df['hum']/100)*(9/5*train_df['hum']-26)+32\n",
        "    test_df['THI'] = 9/5*test_df['temp'] - 0.55*(1-test_df['hum']/100)*(9/5*test_df['hum']-26)+32\n",
        "\n",
        "    # CDH 지수 추가\n",
        "\n",
        "    train_cdhs = np.array([])\n",
        "    for num in range(1,100 + 1,1):\n",
        "      temp = train_df[train_df['building_num'] == num]\n",
        "      cdh = CDH(temp['temp'].values)\n",
        "      train_cdhs = np.concatenate([train_cdhs, cdh])\n",
        "    train_df['CDH'] = train_cdhs\n",
        "\n",
        "    test_cdhs = np.array([])\n",
        "    for num in range(1,100 + 1,1):\n",
        "      temp = test_df[test_df['building_num'] == num]\n",
        "      cdh = CDH(temp['temp'].values)\n",
        "      test_cdhs = np.concatenate([test_cdhs, cdh])\n",
        "    test_df['CDH'] = test_cdhs\n",
        "\n",
        "    sz = train_df.shape[0]\n",
        "\n",
        "    df = pd.concat([train_df, test_df])\n",
        "    df = df.merge(mgrps, on='building_num', how='left')\n",
        "\n",
        "    # add aggregate target features\n",
        "    df = add_feats(df)\n",
        "\n",
        "    # add log target\n",
        "    df[\"log_target\"] = np.log(df.target + 1e-8)\n",
        "\n",
        "    for col in CATE_COLS:\n",
        "        df[col] = df[col].astype(str).astype('category')\n",
        "\n",
        "    # add time index feature\n",
        "    __ix = df.columns.get_loc('datetime')\n",
        "    df['time_idx'] = (df.loc[:, 'datetime'] - df.iloc[0, __ix]).astype('timedelta64[h]').astype('int')\n",
        "\n",
        "    train_df = df.iloc[:sz].copy()\n",
        "    test_df = df.iloc[sz:].copy()\n",
        "\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y4K_DuHMCfNo"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = prep()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Y6gXLpHQ-qcp"
      },
      "outputs": [],
      "source": [
        "include_col = ['location','연면적', '냉방면적', '태양광용량', 'ESS저장용량', 'PCS용량', 'sin_time', 'cos_time', 'sin_day', 'cos_day','num_day_hour_mean', 'num_day_hour_std','건물기타', '공공',\n",
        "       '대학교', '데이터센터', '백화점및아울렛', '병원', '상용', '아파트', '연구소', '지식산업센터', '할인마트',\n",
        "       '호텔및리조트', 'tem_x_hum', 'commute_period', 'THI_group', 'body_temp',\n",
        "       'low_power_day', 'power_diff_ratio', 'power_increase_summer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-4FLU3MgJPNO"
      },
      "outputs": [],
      "source": [
        "include_col = ['location','연면적', '냉방면적', '태양광용량', 'ESS저장용량', 'PCS용량', 'sin_time', 'cos_time', 'sin_day', 'cos_day','num_day_hour_mean', 'num_day_hour_std',\n",
        " 'tem_x_hum', 'commute_period', 'THI_group', 'body_temp',\n",
        "       'low_power_day', 'power_diff_ratio', 'power_increase_summer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v5H-kTX2olin"
      },
      "outputs": [],
      "source": [
        "train_fe = pd.read_csv('train_fe.csv')\n",
        "test_fe = pd.read_csv('test_fe.csv')\n",
        "train_fe = train_fe[include_col]\n",
        "test_fe = test_fe[include_col]\n",
        "\n",
        "train_df = train_df.reset_index(drop = True)\n",
        "train_df = pd.concat([train_df, train_fe],axis=1)\n",
        "\n",
        "test_df = test_df.reset_index(drop = True)\n",
        "test_df = pd.concat([test_df, test_fe],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JpaFwVTnCyOP"
      },
      "outputs": [],
      "source": [
        "CATE_COLS = ['building_num', \"mgrp\", 'holiday', 'dow', 'cluster', 'hot', '건물기타', '공공',\n",
        "       '대학교', '데이터센터', '백화점및아울렛', '병원', '상용', '아파트', '연구소', '지식산업센터', '할인마트',\n",
        "       '호텔및리조트', 'location','연면적', '냉방면적', '태양광용량', 'ESS저장용량', 'PCS용량',\n",
        "             'body_temp',\n",
        "       'low_power_day', 'power_increase_summer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5bWyryloJduU"
      },
      "outputs": [],
      "source": [
        "CATE_COLS = ['building_num', \"mgrp\", 'holiday', 'dow', 'cluster', 'hot', 'location','연면적', '냉방면적', '태양광용량', 'ESS저장용량', 'PCS용량',\n",
        "             'body_temp',\n",
        "       'low_power_day', 'power_increase_summer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0EPbCadWDVoI"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "train_df['건물기타'] = train_df['건물기타'].astype(str)\n",
        "test_df['건물기타'] = test_df['건물기타'].astype(str)\n",
        "train_df['공공'] = train_df['공공'].astype(str)\n",
        "test_df['공공'] = test_df['공공'].astype(str)\n",
        "train_df['대학교'] = train_df['대학교'].astype(str)\n",
        "test_df['대학교'] = test_df['대학교'].astype(str)\n",
        "train_df['데이터센터'] = train_df['데이터센터'].astype(str)\n",
        "test_df['데이터센터'] = test_df['데이터센터'].astype(str)\n",
        "train_df['백화점및아울렛'] = train_df['백화점및아울렛'].astype(str)\n",
        "test_df['백화점및아울렛'] = test_df['백화점및아울렛'].astype(str)\n",
        "train_df['병원'] = train_df['병원'].astype(str)\n",
        "test_df['병원'] = test_df['병원'].astype(str)\n",
        "train_df['상용'] = train_df['상용'].astype(str)\n",
        "test_df['상용'] = test_df['상용'].astype(str)\n",
        "train_df['아파트'] = train_df['아파트'].astype(str)\n",
        "test_df['아파트'] = test_df['아파트'].astype(str)\n",
        "train_df['연구소'] = train_df['연구소'].astype(str)\n",
        "test_df['연구소'] = test_df['연구소'].astype(str)\n",
        "train_df['지식산업센터'] = train_df['지식산업센터'].astype(str)\n",
        "test_df['지식산업센터'] = test_df['지식산업센터'].astype(str)\n",
        "train_df['할인마트'] = train_df['할인마트'].astype(str)\n",
        "test_df['할인마트'] = test_df['할인마트'].astype(str)\n",
        "train_df['호텔및리조트'] = train_df['호텔및리조트'].astype(str)\n",
        "test_df['호텔및리조트'] = test_df['호텔및리조트'].astype(str)\n",
        "'''\n",
        "train_df['location'] = train_df['location'].astype(str)\n",
        "test_df['location'] = test_df['location'].astype(str)\n",
        "\n",
        "train_df['연면적'] = train_df['연면적'].astype(str)\n",
        "test_df['연면적'] = test_df['연면적'].astype(str)\n",
        "\n",
        "train_df['냉방면적'] = train_df['냉방면적'].astype(str)\n",
        "test_df['냉방면적'] = test_df['냉방면적'].astype(str)\n",
        "\n",
        "train_df['태양광용량'] = train_df['태양광용량'].astype(str)\n",
        "test_df['태양광용량'] = test_df['태양광용량'].astype(str)\n",
        "\n",
        "train_df['ESS저장용량'] = train_df['ESS저장용량'].astype(str)\n",
        "test_df['ESS저장용량'] = test_df['ESS저장용량'].astype(str)\n",
        "\n",
        "train_df['PCS용량'] = train_df['PCS용량'].astype(str)\n",
        "test_df['PCS용량'] = test_df['PCS용량'].astype(str)\n",
        "\n",
        "train_df['body_temp'] = train_df['body_temp'].astype(str)\n",
        "test_df['body_temp'] = test_df['body_temp'].astype(str)\n",
        "\n",
        "train_df['low_power_day'] = train_df['low_power_day'].astype(str)\n",
        "test_df['low_power_day'] = test_df['low_power_day'].astype(str)\n",
        "\n",
        "train_df['power_increase_summer'] = train_df['power_increase_summer'].astype(str)\n",
        "test_df['power_increase_summer'] = test_df['power_increase_summer'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIeJZc3Br8Nz",
        "outputId": "87b1baa1-3a87-450c-f11e-c772a70a79c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[None, None, None]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[os.makedirs(p, exist_ok=True) for p in (CKPTROOT, CSVROOT, LOGDIR)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0I9EFh9EUKro"
      },
      "outputs": [],
      "source": [
        "from pytorch_forecasting.data import (\n",
        "    TimeSeriesDataSet,\n",
        "    GroupNormalizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "0GMOk1uIUQL6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def load_dataset(train_df, validate=False):\n",
        "    max_encoder_length = 24 * 7 *ENCODER_LENGTH_IN_WEEKS #5\n",
        "    max_prediction_length = 24 * 7\n",
        "    training_cutoff = train_df['time_idx'].max()-max_prediction_length #2040 - 24*7 = 1871\n",
        "\n",
        "    tr_ds = TimeSeriesDataSet(\n",
        "      train_df[lambda x: x.time_idx <=training_cutoff] if validate else train_df,\n",
        "      time_idx = \"time_idx\",\n",
        "      target = \"target\",\n",
        "      group_ids=[\"building_num\"],\n",
        "      min_encoder_length = 1,\n",
        "      max_encoder_length = max_encoder_length,\n",
        "      min_prediction_length=1,\n",
        "      max_prediction_length=max_prediction_length,\n",
        "\n",
        "      #Known Inputs 알고 있는 변수\n",
        "      time_varying_known_categoricals = CATE_COLS,\n",
        "      time_varying_known_reals=[\n",
        "            \"time_idx\",\n",
        "            'hour',\n",
        "            \"temp\",\n",
        "            \"wind\",\n",
        "            \"hum\",\n",
        "            \"prec\",\n",
        "            'cumhol'\n",
        "        ],\n",
        "      target_normalizer=GroupNormalizer(groups=[\"building_num\"], transformation=\"softplus\"),\n",
        "\n",
        "      #모르고 있는 변수\n",
        "      time_varying_unknown_categoricals=[],\n",
        "      time_varying_unknown_reals=[\n",
        "            \"target\",\n",
        "            \"log_target\",\n",
        "            \"mean_target\",\n",
        "            \"mean_target_num\",\n",
        "            #\"mean_target_mgrp\",\n",
        "            #\"mean_target_cluster\"\n",
        "        ],\n",
        "\n",
        "\n",
        "        add_relative_time_idx=True,  # add as feature\n",
        "        add_target_scales=True,  # add as feature\n",
        "        add_encoder_length=True,  # add as feature\n",
        "\n",
        "        allow_missing_timesteps=True\n",
        "    )\n",
        "\n",
        "\n",
        "    va_ds = None\n",
        "    if validate:\n",
        "        va_ds = TimeSeriesDataSet.from_dataset(\n",
        "        tr_ds, train_df, predict=True, stop_randomization=True\n",
        "    )\n",
        "\n",
        "    return tr_ds, va_ds\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def load_dataset(train_df, validate=True):\n",
        "    max_encoder_length = 24 * 7 *ENCODER_LENGTH_IN_WEEKS #5\n",
        "    max_prediction_length = 24 * 7\n",
        "    training_cutoff = train_df['time_idx'].max()-max_prediction_length #2040 - 24*7 = 1871\n",
        "\n",
        "    tr_ds = TimeSeriesDataSet(\n",
        "      train_df[lambda x: x.time_idx <=training_cutoff] if validate else train_df,\n",
        "      time_idx = \"time_idx\",\n",
        "      target = \"target\",\n",
        "      group_ids=[\"building_num\"],\n",
        "      min_encoder_length = 1,\n",
        "      max_encoder_length = max_encoder_length,\n",
        "      min_prediction_length=1,\n",
        "      max_prediction_length=max_prediction_length,\n",
        "\n",
        "\n",
        "      #Known Inputs 알고 있는 변수\n",
        "      time_varying_known_categoricals = CATE_COLS,\n",
        "      time_varying_known_reals=[\n",
        "            \"time_idx\",\n",
        "            'hour',\n",
        "            \"temp\",\n",
        "            \"wind\",\n",
        "            \"hum\",\n",
        "            \"prec\",\n",
        "            'cumhol',\n",
        "            'sin_time', 'cos_time', 'sin_day', 'cos_day','tem_x_hum'\n",
        "        ],\n",
        "      target_normalizer=GroupNormalizer(groups=[\"building_num\"], transformation=\"softplus\"),\n",
        "\n",
        "      #모르고 있는 변수\n",
        "      time_varying_unknown_categoricals=[],\n",
        "      time_varying_unknown_reals=[\n",
        "            \"target\",\n",
        "            \"log_target\",\n",
        "            \"mean_target\",\n",
        "            \"mean_target_num\",\n",
        "            #\"mean_target_mgrp\",\n",
        "            #\"mean_target_cluster\"\n",
        "            'num_day_hour_mean', 'num_day_hour_std','power_diff_ratio'\n",
        "        ],\n",
        "\n",
        "\n",
        "        add_relative_time_idx=True,  # add as feature\n",
        "        add_target_scales=True,  # add as feature\n",
        "        add_encoder_length=True,  # add as feature\n",
        "\n",
        "        allow_missing_timesteps=True\n",
        "    )\n",
        "    ###\n",
        "    validation = TimeSeriesDataSet.from_dataset(tr_ds, train_df, predict=True, stop_randomization=True)\n",
        "    val_dataloader = validation.to_dataloader(train=False, batch_size=32 * 10, num_workers=12)\n",
        "    ###\n",
        "    '''\n",
        "    va_ds = None\n",
        "    if validate:\n",
        "        va_ds = TimeSeriesDataSet.from_dataset(\n",
        "        tr_ds, train_df, predict=True, stop_randomization=True\n",
        "    )\n",
        "        #va_dl = DataLoader(va_ds, batch_size=64)\n",
        "    '''\n",
        "    return tr_ds, val_dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "G-Iu11JMUSjA"
      },
      "outputs": [],
      "source": [
        "#tr_ds, va_ds = load_dataset(train_df, validate=False)\n",
        "tr_ds, va_ds = load_dataset(train_df, validate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TimeSeriesDataSet[length=100](\n",
              "\ttime_idx='time_idx',\n",
              "\ttarget='target',\n",
              "\tgroup_ids=['building_num'],\n",
              "\tweight=None,\n",
              "\tmax_encoder_length=840,\n",
              "\tmin_encoder_length=1,\n",
              "\tmin_prediction_idx=0,\n",
              "\tmin_prediction_length=168,\n",
              "\tmax_prediction_length=168,\n",
              "\tstatic_categoricals=[],\n",
              "\tstatic_reals=['encoder_length', 'target_center', 'target_scale'],\n",
              "\ttime_varying_known_categoricals=['building_num', 'mgrp', 'holiday', 'dow', 'cluster', 'hot', 'location', '연면적', '냉방면적', '태양광용량', 'ESS저장용량', 'PCS용량', 'body_temp', 'low_power_day', 'power_increase_summer'],\n",
              "\ttime_varying_known_reals=['time_idx', 'hour', 'temp', 'wind', 'hum', 'prec', 'cumhol', 'sin_time', 'cos_time', 'sin_day', 'cos_day', 'tem_x_hum', 'relative_time_idx'],\n",
              "\ttime_varying_unknown_categoricals=[],\n",
              "\ttime_varying_unknown_reals=['target', 'log_target', 'mean_target', 'mean_target_num', 'num_day_hour_mean', 'num_day_hour_std', 'power_diff_ratio'],\n",
              "\tvariable_groups={},\n",
              "\tconstant_fill_strategy={},\n",
              "\tallow_missing_timesteps=True,\n",
              "\tlags={},\n",
              "\tadd_relative_time_idx=True,\n",
              "\tadd_target_scales=True,\n",
              "\tadd_encoder_length=True,\n",
              "\ttarget_normalizer=GroupNormalizer(\n",
              "\tmethod='standard',\n",
              "\tgroups=['building_num'],\n",
              "\tcenter=True,\n",
              "\tscale_by_group=False,\n",
              "\ttransformation='softplus',\n",
              "\tmethod_kwargs={}\n",
              "),\n",
              "\tcategorical_encoders={'__group_id__building_num': NaNLabelEncoder(add_nan=False, warn=True), 'building_num': NaNLabelEncoder(add_nan=False, warn=True), 'mgrp': NaNLabelEncoder(add_nan=False, warn=True), 'holiday': NaNLabelEncoder(add_nan=False, warn=True), 'dow': NaNLabelEncoder(add_nan=False, warn=True), 'cluster': NaNLabelEncoder(add_nan=False, warn=True), 'hot': NaNLabelEncoder(add_nan=False, warn=True), 'location': NaNLabelEncoder(add_nan=False, warn=True), '연면적': NaNLabelEncoder(add_nan=False, warn=True), '냉방면적': NaNLabelEncoder(add_nan=False, warn=True), '태양광용량': NaNLabelEncoder(add_nan=False, warn=True), 'ESS저장용량': NaNLabelEncoder(add_nan=False, warn=True), 'PCS용량': NaNLabelEncoder(add_nan=False, warn=True), 'body_temp': NaNLabelEncoder(add_nan=False, warn=True), 'low_power_day': NaNLabelEncoder(add_nan=False, warn=True), 'power_increase_summer': NaNLabelEncoder(add_nan=False, warn=True)},\n",
              "\tscalers={'encoder_length': StandardScaler(), 'target_center': StandardScaler(), 'target_scale': StandardScaler(), 'time_idx': StandardScaler(), 'hour': StandardScaler(), 'temp': StandardScaler(), 'wind': StandardScaler(), 'hum': StandardScaler(), 'prec': StandardScaler(), 'cumhol': StandardScaler(), 'sin_time': StandardScaler(), 'cos_time': StandardScaler(), 'sin_day': StandardScaler(), 'cos_day': StandardScaler(), 'tem_x_hum': StandardScaler(), 'relative_time_idx': StandardScaler(), 'log_target': StandardScaler(), 'mean_target': StandardScaler(), 'mean_target_num': StandardScaler(), 'num_day_hour_mean': StandardScaler(), 'num_day_hour_std': StandardScaler(), 'power_diff_ratio': StandardScaler()},\n",
              "\trandomize_length=None,\n",
              "\tpredict_mode=True\n",
              ")"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "va_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "K40RjKDIWa59"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "def fit(seed, tr_ds, va_loader=None):\n",
        "    seed_all(seed) # doesn't really work as training is non-deterministic\n",
        "\n",
        "    # create dataloaders for model\n",
        "    tr_loader = tr_ds.to_dataloader(\n",
        "        train=True, batch_size=BATCH_SIZE, num_workers=12\n",
        "    )\n",
        "\n",
        "    if va_loader is not None:\n",
        "        # stop training, when loss metric does not improve on validation set\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor=\"val_loss\",\n",
        "            min_delta=1e-4,\n",
        "            patience=20,\n",
        "            verbose=True,\n",
        "            mode=\"min\"\n",
        "        )\n",
        "        lr_logger = LearningRateMonitor(logging_interval=\"epoch\")  # log the learning rate\n",
        "        callbacks = [lr_logger, early_stopping_callback]\n",
        "    else:\n",
        "        # gather 10 checkpoints with best traing loss\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            monitor='train_loss',\n",
        "            dirpath=CKPTROOT,\n",
        "            filename=f'seed={seed}'+'-{epoch:03d}-{train_loss:.2f}',\n",
        "            save_top_k=10\n",
        "        )\n",
        "        callbacks = [checkpoint_callback]\n",
        "\n",
        "    # create trainer\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=60,\n",
        "        devices=1,\n",
        "        accelerator=\"gpu\",\n",
        "        gradient_clip_val=PARAMS['gradient_clip_val'],\n",
        "        limit_train_batches=30,\n",
        "        callbacks=callbacks,\n",
        "        logger=TensorBoardLogger(LOGDIR)\n",
        "    )\n",
        "\n",
        "    # use pre-deterined leraning rate schedule for final submission\n",
        "    learning_rate = LRS if va_loader is None else PARAMS['learning_rate']\n",
        "\n",
        "    # initialise model with pre-determined hyperparameters\n",
        "    tft = TemporalFusionTransformer.from_dataset(\n",
        "        tr_ds,\n",
        "        learning_rate=learning_rate,\n",
        "        hidden_size=PARAMS['hidden_size'],\n",
        "        attention_head_size=PARAMS['attention_head_size'],\n",
        "        dropout=PARAMS['dropout'],\n",
        "        hidden_continuous_size=PARAMS['hidden_continuous_size'],\n",
        "        output_size=1,\n",
        "        loss=SMAPE(), # SMAPE loss\n",
        "        log_interval=10,  # log example every 10 batches\n",
        "        logging_metrics=[SMAPE()],\n",
        "        reduce_on_plateau_patience=4,  # reduce learning automatically\n",
        "    )\n",
        "    print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n",
        "\n",
        "    kwargs = {'train_dataloaders': tr_loader}\n",
        "    if va_loader:\n",
        "        kwargs['val_dataloaders'] = va_loader\n",
        "\n",
        "    # fit network\n",
        "    trainer.fit(\n",
        "        tft,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "    print(f'best_model_path={best_model_path}')\n",
        "    best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
        "\n",
        "    return best_tft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "# training\n",
        "def tune_and_fit(seed, tr_ds, va_loader):\n",
        "    seed_all(seed) # doesn't really work as training is non-deterministic\n",
        "\n",
        "    # create dataloaders for model\n",
        "    tr_loader = tr_ds.to_dataloader(\n",
        "        train=True, batch_size=BATCH_SIZE, num_workers=12\n",
        "    )\n",
        "    #val_loader = va_loader.to_dataloader(\n",
        "    #    train=False, batch_size=BATCH_SIZE, num_workers=12\n",
        "    #)\n",
        "    \n",
        "    if va_loader is not None:\n",
        "        # stop training, when loss metric does not improve on validation set\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor=\"val_loss\",\n",
        "            min_delta=1e-4,\n",
        "            patience=20,\n",
        "            verbose=True,\n",
        "            mode=\"min\"\n",
        "        )\n",
        "        lr_logger = LearningRateMonitor(logging_interval=\"epoch\")  # log the learning rate\n",
        "        callbacks = [lr_logger, early_stopping_callback]\n",
        "    else:\n",
        "        # gather 10 checkpoints with best traing loss\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            monitor='train_loss',\n",
        "            dirpath=CKPTROOT,\n",
        "            filename=f'seed={seed}'+'-{epoch:03d}-{train_loss:.2f}',\n",
        "            save_top_k=10\n",
        "        )\n",
        "        callbacks = [checkpoint_callback]\n",
        "\n",
        "\n",
        "    \n",
        "    # create study\n",
        "    study = optimize_hyperparameters(\n",
        "        tr_loader,\n",
        "        va_loader,\n",
        "        model_path=\"optuna_test\",\n",
        "        n_trials=1,\n",
        "        max_epochs=3, #20\n",
        "        gradient_clip_val_range=(0.01, 1.0),\n",
        "        hidden_size_range=(8, 64),\n",
        "        hidden_continuous_size_range=(8, 64),\n",
        "        attention_head_size_range=(1, 4),\n",
        "        learning_rate_range=(0.001, 0.1),\n",
        "        dropout_range=(0.1, 0.3),\n",
        "        trainer_kwargs=dict(limit_train_batches=100, limit_test_batches=100, limit_val_batches=100, log_every_n_steps=15, gpus=1),\n",
        "        reduce_on_plateau_patience=4,\n",
        "        use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
        "        timeout=7200  # we can increase the timTRUEeout for better tuning.\n",
        "    )\n",
        "    # show best hyperparameters\n",
        "    print(study.best_trial.params)\n",
        "    # Retrain the full model\n",
        "    #Early Stopping \n",
        "    MIN_DELTA  = 1e-4\n",
        "    PATIENCE = 20\n",
        "\n",
        "    #PL Trainer\n",
        "    MAX_EPOCHS = 2   # this also one of the tuning parameters to imporve the score.\n",
        "    GPUS = 1\n",
        "    GRADIENT_CLIP_VAL=study.best_trial.params['gradient_clip_val']\n",
        "    LIMIT_TRAIN_BATCHES=30\n",
        "\n",
        "    #Fusion Transformer\n",
        "    LR = study.best_trial.params['learning_rate']\n",
        "    HIDDEN_SIZE = study.best_trial.params['hidden_size']\n",
        "    DROPOUT = study.best_trial.params['dropout']\n",
        "    ATTENTION_HEAD_SIZE = study.best_trial.params['attention_head_size']\n",
        "    HIDDEN_CONTINUOUS_SIZE = study.best_trial.params['hidden_continuous_size']\n",
        "    OUTPUT_SIZE=1\n",
        "    REDUCE_ON_PLATEAU_PATIENCE=4          \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # create trainer\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=60,\n",
        "        devices=1,\n",
        "        accelerator=\"gpu\",\n",
        "        gradient_clip_val=PARAMS['gradient_clip_val'],\n",
        "        limit_train_batches=30,\n",
        "        callbacks=callbacks,\n",
        "        logger=TensorBoardLogger(LOGDIR)\n",
        "    )\n",
        "\n",
        "    # use pre-deterined leraning rate schedule for final submission\n",
        "    learning_rate = LRS if va_loader is None else PARAMS['learning_rate']\n",
        "\n",
        "    # initialise model with pre-determined hyperparameters\n",
        "    tft = TemporalFusionTransformer.from_dataset(\n",
        "        tr_ds,\n",
        "        learning_rate=LR,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        attention_head_size=ATTENTION_HEAD_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        hidden_continuous_size=HIDDEN_CONTINUOUS_SIZE,\n",
        "        output_size=1,\n",
        "        loss=SMAPE(), # SMAPE loss\n",
        "        log_interval=10,  # log example every 10 batches\n",
        "        logging_metrics=[SMAPE()],\n",
        "        reduce_on_plateau_patience=4,  # reduce learning automatically\n",
        "    )\n",
        "    print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n",
        "\n",
        "    kwargs = {'train_dataloaders': tr_loader}\n",
        "    if va_loader:\n",
        "        kwargs['val_dataloaders'] = va_loader\n",
        "\n",
        "    # fit network\n",
        "    trainer.fit(\n",
        "        tft,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "    print(f'best_model_path={best_model_path}')\n",
        "    best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
        "\n",
        "    return best_tft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-07-26 02:35:57,855]\u001b[0m A new study created in memory with name: no-name-4c17bc7f-9d13-4539-b7c8-f3a33425cdc0\u001b[0m\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:269: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
            "  rank_zero_warn(\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:613: UserWarning: Checkpoint directory C:\\Users\\USER\\Desktop\\electric\\electric_DL\\optuna_test\\trial_0 exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\integration\\pytorch_lightning.py:52: UserWarning: The metric 'val_loss' is not in the evaluation logs for pruning. Please make sure you set the correct metric name.\n",
            "  warnings.warn(message)\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "\u001b[33m[W 2023-07-26 02:36:04,632]\u001b[0m Trial 0 failed because of the following error: KeyError('val_loss')\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\tuning.py\", line 212, in objective\n",
            "    return metrics_callback.metrics[-1][\"val_loss\"].item()\n",
            "KeyError: 'val_loss'\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'val_loss'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\USER\\Desktop\\electric\\electric_DL\\TFT.ipynb Cell 25\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m seed\u001b[39m=\u001b[39m[\u001b[39m724\u001b[39m, \u001b[39m313\u001b[39m, \u001b[39m9377\u001b[39m, \u001b[39m9555\u001b[39m, \u001b[39m126\u001b[39m, \u001b[39m877\u001b[39m, \u001b[39m7777\u001b[39m, \u001b[39m1004\u001b[39m, \u001b[39m725\u001b[39m, \u001b[39m4598723\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m seed:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     tune_and_fit(s, tr_ds, va_ds)\n",
            "\u001b[1;32mc:\\Users\\USER\\Desktop\\electric\\electric_DL\\TFT.ipynb Cell 25\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     callbacks \u001b[39m=\u001b[39m [checkpoint_callback]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# create study\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m study \u001b[39m=\u001b[39m optimize_hyperparameters(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     tr_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     va_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     model_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moptuna_test\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     n_trials\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, \u001b[39m#20\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     gradient_clip_val_range\u001b[39m=\u001b[39;49m(\u001b[39m0.01\u001b[39;49m, \u001b[39m1.0\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     hidden_size_range\u001b[39m=\u001b[39;49m(\u001b[39m8\u001b[39;49m, \u001b[39m64\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     hidden_continuous_size_range\u001b[39m=\u001b[39;49m(\u001b[39m8\u001b[39;49m, \u001b[39m64\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     attention_head_size_range\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39m4\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     learning_rate_range\u001b[39m=\u001b[39;49m(\u001b[39m0.001\u001b[39;49m, \u001b[39m0.1\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     dropout_range\u001b[39m=\u001b[39;49m(\u001b[39m0.1\u001b[39;49m, \u001b[39m0.3\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     trainer_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(limit_train_batches\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, limit_test_batches\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, limit_val_batches\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, log_every_n_steps\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m, gpus\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     reduce_on_plateau_patience\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     use_learning_rate_finder\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# use Optuna to find ideal learning rate or use in-built learning rate finder\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39m7200\u001b[39;49m  \u001b[39m# we can increase the timTRUEeout for better tuning.\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# show best hyperparameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X42sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\tuning.py:217\u001b[0m, in \u001b[0;36moptimize_hyperparameters\u001b[1;34m(train_dataloaders, val_dataloaders, model_path, max_epochs, n_trials, timeout, gradient_clip_val_range, hidden_size_range, hidden_continuous_size_range, attention_head_size_range, dropout_range, learning_rate_range, use_learning_rate_finder, trainer_kwargs, log_dir, study, verbose, pruner, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m study \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m, pruner\u001b[39m=\u001b[39mpruner)\n\u001b[1;32m--> 217\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49mn_trials, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m study\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 400\u001b[0m _optimize(\n\u001b[0;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    410\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m show_progress_bar:\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\_optimize.py:264\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch):\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m trial\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    210\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\tuning.py:212\u001b[0m, in \u001b[0;36moptimize_hyperparameters.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    209\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders)\n\u001b[0;32m    211\u001b[0m \u001b[39m# report result\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m metrics_callback\u001b[39m.\u001b[39;49mmetrics[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mitem()\n",
            "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
          ]
        }
      ],
      "source": [
        "#3060으로 3에포크 15분~20분\n",
        "\n",
        "#seed=[17, 1218, 20230725, 1998, 32, 40, 800, 6651, 4931, 18011810]\n",
        "seed=[724, 313, 9377, 9555, 126, 877, 7777, 1004, 725, 4598723]\n",
        "\n",
        "for s in seed:\n",
        "    tune_and_fit(s, tr_ds, va_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "47e1d228e850444b9e1ddd74dd100e9d",
            "ad3043bbf27e4638894191f46a24f3d1",
            "b4308cdbee4349c9aea372c8b9ac54a7",
            "c2b933e56904499ea674eaf697b41ba5",
            "b67c3c601b02419fb83550d34806888f",
            "8a5ec381b80d402395cc88ab774d52d1",
            "d58f3ed3dc124b5f8b6ef66d4c47ebec",
            "fce3b01edb3e48829e72b16b96058f36",
            "7ac38d75d3c843bc931c70c7babc750c",
            "5a4d33521b5243e1b10cbfa7e01a877c",
            "30f52fdee53f484a83e32992d0233bb3",
            "8f2bf5dad2ff4af3b69f4939e4b42b7a",
            "9bef7471c08045e6911ef4b1e2c486fa",
            "3c40750f9eaf4d788d09f8b0835173f3",
            "d3a4bebcca8e4936a8481af586cc2346",
            "da549d06fb1541898bc148adde975e38",
            "4a76428b4c144ca7b93a2a3b0f202a1c",
            "d61a78df206c47fdbcbe7fc1fa089614",
            "dfe8196d0b8f44f99797cecb83f48be9",
            "a5e7b4d7ce8740a1b16ec87d62cc86d9",
            "3a8a6d60441f40debb4685e5da611781",
            "e864787202aa4c51bf895b5a45d137ee",
            "bd7dba01b63f410894f73f7152e413e4",
            "72de65a65466420cb1048830d5967e81",
            "ddf8d4f3074a47e4af9ccd85564309a9",
            "37234a85925945cf956edfc092db0937",
            "83e3659953c0488db4baec7f944becb7",
            "32b75c4f3c964d26a7a4343d4fa89c6e",
            "d9352a97fed14d8ba729ca72b4fb42e7",
            "1aa6f1c302e94fe6b2ff724d2b95bca3",
            "b850a5b3a3034134b39b2654aefc3e5e",
            "0b7ebf7fb3d24cb9af44913a99ff5528",
            "7b70f713d026491ab6c7ce1e55664ef6"
          ]
        },
        "id": "bfNxtL_0Wfyi",
        "outputId": "5bc09943-3ca0-47a6-aa2c-c0d4093b3174"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters in network: 3567.4k\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "   | Name                               | Type                            | Params\n",
            "----------------------------------------------------------------------------------------\n",
            "0  | loss                               | SMAPE                           | 0     \n",
            "1  | logging_metrics                    | ModuleList                      | 0     \n",
            "2  | input_embeddings                   | MultiEmbedding                  | 7.4 K \n",
            "3  | prescalers                         | ModuleDict                      | 4.1 K \n",
            "4  | static_variable_selection          | VariableSelectionNetwork        | 151 K \n",
            "5  | encoder_variable_selection         | VariableSelectionNetwork        | 1.1 M \n",
            "6  | decoder_variable_selection         | VariableSelectionNetwork        | 704 K \n",
            "7  | static_context_variable_selection  | GatedResidualNetwork            | 130 K \n",
            "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 130 K \n",
            "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 130 K \n",
            "10 | static_context_enrichment          | GatedResidualNetwork            | 130 K \n",
            "11 | lstm_encoder                       | LSTM                            | 260 K \n",
            "12 | lstm_decoder                       | LSTM                            | 260 K \n",
            "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 65.2 K\n",
            "14 | post_lstm_add_norm_encoder         | AddNorm                         | 360   \n",
            "15 | static_enrichment                  | GatedResidualNetwork            | 163 K \n",
            "16 | multihead_attn                     | InterpretableMultiHeadAttention | 81.4 K\n",
            "17 | post_attn_gate_norm                | GateAddNorm                     | 65.5 K\n",
            "18 | pos_wise_ff                        | GatedResidualNetwork            | 130 K \n",
            "19 | pre_output_gate_norm               | GateAddNorm                     | 65.5 K\n",
            "20 | output_layer                       | Linear                          | 181   \n",
            "----------------------------------------------------------------------------------------\n",
            "3.6 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.6 M     Total params\n",
            "14.269    Total estimated model params size (MB)\n",
            "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1609: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.01000833511352539,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Training",
              "rate": null,
              "total": null,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b78b14e2ccf44da09be5d504937a05fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.26 GiB (GPU 0; 12.00 GiB total capacity; 9.46 GiB already allocated; 0 bytes free; 10.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\USER\\Desktop\\electric\\electric_DL\\TFT.ipynb Cell 23\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m seed\u001b[39m=\u001b[39m[\u001b[39m724\u001b[39m, \u001b[39m313\u001b[39m, \u001b[39m9377\u001b[39m, \u001b[39m9555\u001b[39m, \u001b[39m126\u001b[39m, \u001b[39m877\u001b[39m, \u001b[39m7777\u001b[39m, \u001b[39m1004\u001b[39m, \u001b[39m725\u001b[39m, \u001b[39m4598723\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m seed:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     fit(s, tr_ds)\n",
            "\u001b[1;32mc:\\Users\\USER\\Desktop\\electric\\electric_DL\\TFT.ipynb Cell 23\u001b[0m in \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mval_dataloaders\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m va_loader\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# fit network\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     tft,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m best_model_path \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mcheckpoint_callback\u001b[39m.\u001b[39mbest_model_path\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/electric/electric_DL/TFT.ipynb#X32sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbest_model_path=\u001b[39m\u001b[39m{\u001b[39;00mbest_model_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[0;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    610\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[0;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[1;32m-> 1112\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m   1114\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m   1190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1214\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m   1213\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(dataloader, batch_to_device\u001b[39m=\u001b[39mbatch_to_device)\n\u001b[0;32m    266\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py:213\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[0;32m    212\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 213\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_loop\u001b[39m.\u001b[39;49mrun(kwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[0;32m    217\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\batch\\training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[0;32m     85\u001b[0m     optimizers \u001b[39m=\u001b[39m _get_active_optimizers(\n\u001b[0;32m     86\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizer_frequencies, kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbatch_idx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m     87\u001b[0m     )\n\u001b[1;32m---> 88\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_loop\u001b[39m.\u001b[39;49mrun(optimizers, kwargs)\n\u001b[0;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_loop\u001b[39m.\u001b[39mrun(kwargs)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:202\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[1;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madvance\u001b[39m(\u001b[39mself\u001b[39m, optimizers: List[Tuple[\u001b[39mint\u001b[39m, Optimizer]], kwargs: OrderedDict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_kwargs(kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hiddens)\n\u001b[1;32m--> 202\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_optimization(kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizers[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptim_progress\u001b[39m.\u001b[39;49moptimizer_position])\n\u001b[0;32m    203\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m         \u001b[39m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[0;32m    205\u001b[0m         \u001b[39m# would be skipped otherwise\u001b[39;00m\n\u001b[0;32m    206\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39masdict()\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:249\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[1;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[0;32m    241\u001b[0m         closure()\n\u001b[0;32m    243\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# the `batch_idx` is optional with inter-batch parallelism\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(optimizer, opt_idx, kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[0;32m    251\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[0;32m    253\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     \u001b[39m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     \u001b[39m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[39m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:370\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    362\u001b[0m     rank_zero_deprecation(\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m return True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    368\u001b[0m     )\n\u001b[0;32m    369\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39musing_native_amp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprecision_plugin, MixedPrecisionPlugin)\n\u001b[1;32m--> 370\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[0;32m    371\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    372\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[0;32m    373\u001b[0m     batch_idx,\n\u001b[0;32m    374\u001b[0m     optimizer,\n\u001b[0;32m    375\u001b[0m     opt_idx,\n\u001b[0;32m    376\u001b[0m     train_step_and_backward_closure,\n\u001b[0;32m    377\u001b[0m     on_tpu\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator, TPUAccelerator),\n\u001b[0;32m    378\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    379\u001b[0m     using_lbfgs\u001b[39m=\u001b[39;49mis_lbfgs,\n\u001b[0;32m    380\u001b[0m )\n\u001b[0;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1356\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[1;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1353\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[0;32m   1355\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1356\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1358\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1742\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_lbfgs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[0;32m   1664\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1665\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1671\u001b[0m     using_lbfgs: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1672\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1673\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1674\u001b[0m \u001b[39m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1675\u001b[0m \u001b[39m    each optimizer.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1740\u001b[0m \n\u001b[0;32m   1741\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1742\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:169\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[0;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:234\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[1;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(\n\u001b[0;32m    235\u001b[0m     optimizer, model\u001b[39m=\u001b[39;49mmodel, optimizer_idx\u001b[39m=\u001b[39;49mopt_idx, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    236\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:119\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[1;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[1;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     67\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_forecasting\\optim.py:143\u001b[0m, in \u001b[0;36mRanger.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, closure: OptLossClosure \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OptFloat:\n\u001b[0;32m    139\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs a single optimization step.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[39m    Arguments:\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39m        closure: A closure that reevaluates the model and returns the loss.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     _ \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    144\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[39m# note - below is commented out b/c I have other work that passes back\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# the loss as a float, and thus not a callable closure.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[39m# Uncomment if you need to use the actual closure...\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[39m# loss = closure()\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[39m# Evaluate averages and grad, update param tensors\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:105\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[1;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[0;32m     93\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     94\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m     98\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     99\u001b[0m     \u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[0;32m    102\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[0;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:149\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:144\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_fn()\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward_fn(step_output\u001b[39m.\u001b[39;49mclosure_loss)\n\u001b[0;32m    146\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py:305\u001b[0m, in \u001b[0;36mOptimizerLoop._make_backward_fn.<locals>.backward_fn\u001b[1;34m(loss)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_fn\u001b[39m(loss: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mbackward\u001b[39;49m\u001b[39m\"\u001b[39;49m, loss, optimizer, opt_idx)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1491\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1494\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1496\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:207\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[1;34m(self, closure_loss, optimizer, optimizer_idx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    205\u001b[0m closure_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mpre_backward(closure_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[1;32m--> 207\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49mbackward(closure_loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module, optimizer, optimizer_idx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    209\u001b[0m closure_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mpost_backward(closure_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[0;32m    210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_backward(closure_loss)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:67\u001b[0m, in \u001b[0;36mPrecisionPlugin.backward\u001b[1;34m(self, tensor, model, optimizer, optimizer_idx, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     49\u001b[0m     tensor: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m     55\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m        \\**kwargs: Keyword arguments for the same purpose as ``*args``.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     model\u001b[39m.\u001b[39;49mbackward(tensor, optimizer, optimizer_idx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1486\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[1;34m(self, loss, optimizer, optimizer_idx, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fabric\u001b[39m.\u001b[39mbackward(loss, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1485\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.26 GiB (GPU 0; 12.00 GiB total capacity; 9.46 GiB already allocated; 0 bytes free; 10.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "#seed=[17, 1218, 20230725, 1998, 32, 40, 800, 6651, 4931, 18011810]\n",
        "seed=[724, 313, 9377, 9555, 126, 877, 7777, 1004, 725, 4598723]\n",
        "for s in seed:\n",
        "    fit(s, tr_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KG57yZNWwkr"
      },
      "outputs": [],
      "source": [
        "# predict 1 week\n",
        "def forecast(ckpt, train_df, test_df):\n",
        "    # load model\n",
        "    best_tft = TemporalFusionTransformer.load_from_checkpoint(ckpt)\n",
        "    max_encoder_length = best_tft.dataset_parameters['max_encoder_length']\n",
        "    max_prediction_length = best_tft.dataset_parameters['max_prediction_length']\n",
        "\n",
        "    assert max_encoder_length == 5*24*7 and max_prediction_length == 1*24*7\n",
        "\n",
        "    # use 5 weeks of training data at the end\n",
        "    encoder_data = train_df[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
        "\n",
        "    # get last entry from training data\n",
        "    last_data = train_df.iloc[[-1]]\n",
        "\n",
        "    # fill NA target value in test data with last values from the train dataset\n",
        "    target_cols = [c for c in test_df.columns if 'target' in c]\n",
        "    for c in target_cols:\n",
        "        test_df.loc[:, c] = last_data[c].item()\n",
        "\n",
        "    decoder_data = test_df\n",
        "\n",
        "    # combine encoder and decoder data. decoder data is to be predicted\n",
        "    new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
        "    new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)\n",
        "\n",
        "    # num_labels: mapping from 'num' categorical feature to index in new_raw_predictions['prediction']\n",
        "    #             {'5': 4, '6': 6, ...}\n",
        "    # new_raw_predictions['prediction'].shape = (60, 168, 1)\n",
        "    num_labels = best_tft.dataset_parameters['categorical_encoders']['building_num'].classes_\n",
        "\n",
        "    preds = new_raw_predictions['prediction'].squeeze()\n",
        "\n",
        "    sub_df = pd.read_csv(DATAROOT+\"/sample_submission.csv\")\n",
        "\n",
        "    # get prediction for each building (num)\n",
        "    for n, ix in num_labels.items():\n",
        "        sub_df.loc[(sub_df['num_date_time'].apply(lambda x : int(x.split('_')[0])) == int(n)), 'answer'] = preds[ix].numpy()\n",
        "\n",
        "    # save predction to a csv file\n",
        "    outfn = CSVROOT+'/'+(Path(ckpt).stem + '.csv')\n",
        "    print(outfn)\n",
        "    sub_df.to_csv(outfn, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbe9CInWWyPE"
      },
      "outputs": [],
      "source": [
        "def ensemble(outfn):\n",
        "    # get all prediction csv files\n",
        "    fns = list(glob.glob(CSVROOT+\"/*.csv\"))\n",
        "    df0 = pd.read_csv(fns[0])\n",
        "    df = pd.concat([df0] + [pd.read_csv(fn).loc[:,'answer'] for fn in fns[1:]], axis=1)\n",
        "    # get median of all predcitions\n",
        "    df['median'] = df.iloc[:,1:].median(axis=1)\n",
        "    df = df[['num_date_time', 'median']]\n",
        "    df = df.rename({'median': 'answer'}, axis=1)\n",
        "    # save to submission file\n",
        "    df.to_csv(outfn, index=False)\n",
        "\n",
        "# not used for final submission\n",
        "def validate(seed, tr_ds, va_ds):\n",
        "    va_loader = va_ds.to_dataloader(\n",
        "        train=False, batch_size=BATCH_SIZE*10, num_workers=12\n",
        "    )\n",
        "    best_tft = fit(seed, tr_ds, va_loader)\n",
        "    actuals = torch.cat([y[0] for x, y in iter(va_loader)])\n",
        "    predictions = best_tft.predict(va_loader)\n",
        "    smape_per_num = SMAPE(reduction=\"none\")(predictions, actuals).mean(1)\n",
        "    print(smape_per_num)\n",
        "    print(smape_per_num.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "71o495MEW0DG",
        "outputId": "7c78b4a9-9d55-40dd-b62b-2ee28585c76f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### FORECAST ###\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=050-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=051-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=052-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=053-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=054-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=055-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=056-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=057-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=058-train_loss=0.04.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/electric/csvs/seed=724-epoch=059-train_loss=0.04.csv\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "print(\"### FORECAST ###\")\n",
        "for p in glob.glob(CKPTROOT + \"/*.ckpt\"):\n",
        "    forecast(p, train_df, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cszDHJ5nW02Q",
        "outputId": "052a44a7-c004-4b52-cc64-cc2f5751d9d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### ENSEMBLING ###\n"
          ]
        }
      ],
      "source": [
        "print(\"### ENSEMBLING ###\")\n",
        "ensemble(CSVROOT + 'submit_v21.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0t4iiOM4l-zy",
        "outputId": "af9a1641-3fec-4e7c-d7f9-c2e07e3b2805"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-212e9fcc-be0f-4acd-ad12-6a546a9a9f7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_date_time</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_20220825 00</td>\n",
              "      <td>1870.348633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_20220825 01</td>\n",
              "      <td>1756.653076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_20220825 02</td>\n",
              "      <td>1644.968323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_20220825 03</td>\n",
              "      <td>1568.214905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_20220825 04</td>\n",
              "      <td>1601.211426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16795</th>\n",
              "      <td>100_20220831 19</td>\n",
              "      <td>880.414734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16796</th>\n",
              "      <td>100_20220831 20</td>\n",
              "      <td>800.949615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16797</th>\n",
              "      <td>100_20220831 21</td>\n",
              "      <td>730.718262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16798</th>\n",
              "      <td>100_20220831 22</td>\n",
              "      <td>623.565460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16799</th>\n",
              "      <td>100_20220831 23</td>\n",
              "      <td>517.228210</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-212e9fcc-be0f-4acd-ad12-6a546a9a9f7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a7baf15d-e39b-41c2-ae6f-131bf91fb001\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7baf15d-e39b-41c2-ae6f-131bf91fb001')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a7baf15d-e39b-41c2-ae6f-131bf91fb001 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-212e9fcc-be0f-4acd-ad12-6a546a9a9f7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-212e9fcc-be0f-4acd-ad12-6a546a9a9f7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         num_date_time       answer\n",
              "0        1_20220825 00  1870.348633\n",
              "1        1_20220825 01  1756.653076\n",
              "2        1_20220825 02  1644.968323\n",
              "3        1_20220825 03  1568.214905\n",
              "4        1_20220825 04  1601.211426\n",
              "...                ...          ...\n",
              "16795  100_20220831 19   880.414734\n",
              "16796  100_20220831 20   800.949615\n",
              "16797  100_20220831 21   730.718262\n",
              "16798  100_20220831 22   623.565460\n",
              "16799  100_20220831 23   517.228210\n",
              "\n",
              "[16800 rows x 2 columns]"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = pd.read_csv(CSVROOT + 'submit_v21.csv')\n",
        "a"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b7ebf7fb3d24cb9af44913a99ff5528": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa6f1c302e94fe6b2ff724d2b95bca3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f52fdee53f484a83e32992d0233bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32b75c4f3c964d26a7a4343d4fa89c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37234a85925945cf956edfc092db0937": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7ebf7fb3d24cb9af44913a99ff5528",
            "placeholder": "​",
            "style": "IPY_MODEL_7b70f713d026491ab6c7ce1e55664ef6",
            "value": " 0/30 [00:00&lt;?, ?it/s]"
          }
        },
        "3a8a6d60441f40debb4685e5da611781": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c40750f9eaf4d788d09f8b0835173f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfe8196d0b8f44f99797cecb83f48be9",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5e7b4d7ce8740a1b16ec87d62cc86d9",
            "value": 0
          }
        },
        "47e1d228e850444b9e1ddd74dd100e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad3043bbf27e4638894191f46a24f3d1",
              "IPY_MODEL_b4308cdbee4349c9aea372c8b9ac54a7",
              "IPY_MODEL_c2b933e56904499ea674eaf697b41ba5"
            ],
            "layout": "IPY_MODEL_b67c3c601b02419fb83550d34806888f"
          }
        },
        "4a76428b4c144ca7b93a2a3b0f202a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a4d33521b5243e1b10cbfa7e01a877c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72de65a65466420cb1048830d5967e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b75c4f3c964d26a7a4343d4fa89c6e",
            "placeholder": "​",
            "style": "IPY_MODEL_d9352a97fed14d8ba729ca72b4fb42e7",
            "value": "Epoch 0:   0%"
          }
        },
        "7ac38d75d3c843bc931c70c7babc750c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b70f713d026491ab6c7ce1e55664ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e3659953c0488db4baec7f944becb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8a5ec381b80d402395cc88ab774d52d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2bf5dad2ff4af3b69f4939e4b42b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bef7471c08045e6911ef4b1e2c486fa",
              "IPY_MODEL_3c40750f9eaf4d788d09f8b0835173f3",
              "IPY_MODEL_d3a4bebcca8e4936a8481af586cc2346"
            ],
            "layout": "IPY_MODEL_da549d06fb1541898bc148adde975e38"
          }
        },
        "9bef7471c08045e6911ef4b1e2c486fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a76428b4c144ca7b93a2a3b0f202a1c",
            "placeholder": "​",
            "style": "IPY_MODEL_d61a78df206c47fdbcbe7fc1fa089614",
            "value": "Epoch 3:   0%"
          }
        },
        "a5e7b4d7ce8740a1b16ec87d62cc86d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad3043bbf27e4638894191f46a24f3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a5ec381b80d402395cc88ab774d52d1",
            "placeholder": "​",
            "style": "IPY_MODEL_d58f3ed3dc124b5f8b6ef66d4c47ebec",
            "value": "Epoch 59: 100%"
          }
        },
        "b4308cdbee4349c9aea372c8b9ac54a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce3b01edb3e48829e72b16b96058f36",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ac38d75d3c843bc931c70c7babc750c",
            "value": 30
          }
        },
        "b67c3c601b02419fb83550d34806888f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b850a5b3a3034134b39b2654aefc3e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd7dba01b63f410894f73f7152e413e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72de65a65466420cb1048830d5967e81",
              "IPY_MODEL_ddf8d4f3074a47e4af9ccd85564309a9",
              "IPY_MODEL_37234a85925945cf956edfc092db0937"
            ],
            "layout": "IPY_MODEL_83e3659953c0488db4baec7f944becb7"
          }
        },
        "c2b933e56904499ea674eaf697b41ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a4d33521b5243e1b10cbfa7e01a877c",
            "placeholder": "​",
            "style": "IPY_MODEL_30f52fdee53f484a83e32992d0233bb3",
            "value": " 30/30 [01:18&lt;00:00,  2.63s/it, loss=0.0364, v_num=9, train_loss_step=0.0365, train_loss_epoch=0.0364]"
          }
        },
        "d3a4bebcca8e4936a8481af586cc2346": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8a6d60441f40debb4685e5da611781",
            "placeholder": "​",
            "style": "IPY_MODEL_e864787202aa4c51bf895b5a45d137ee",
            "value": " 0/30 [04:33&lt;?, ?it/s, loss=0.157, v_num=10, train_loss_step=0.138, train_loss_epoch=0.157]"
          }
        },
        "d58f3ed3dc124b5f8b6ef66d4c47ebec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d61a78df206c47fdbcbe7fc1fa089614": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9352a97fed14d8ba729ca72b4fb42e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da549d06fb1541898bc148adde975e38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "ddf8d4f3074a47e4af9ccd85564309a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aa6f1c302e94fe6b2ff724d2b95bca3",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b850a5b3a3034134b39b2654aefc3e5e",
            "value": 0
          }
        },
        "dfe8196d0b8f44f99797cecb83f48be9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e864787202aa4c51bf895b5a45d137ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fce3b01edb3e48829e72b16b96058f36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
